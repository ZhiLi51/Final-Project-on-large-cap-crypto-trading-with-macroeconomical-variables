{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Cryptocurrencies are fast becoming rivals to traditional currency across the world. The digital currencies are available to purchase in many different places, making it accessible to everyone, and with retailers accepting various cryptocurrencies it could be a sign that money as we know it is about to go through a major change.\n",
    "\n",
    "In addition, the blockchain technology on which many cryptocurrencies are based, with its revolutionary distributed digital backbone, has many other promising applications. Implementations of secure, decentralized systems can aid us in conquering organizational issues of trust and security that have plagued our society throughout the ages. In effect, we can fundamentally \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "# Bitcoin Price Prediction\n",
    "\n",
    "The goal of this case study is to use classification based models to predict whether the current signal is **buy or sell** depending on the short term vs long term price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Libraries and Dataset](#1)\n",
    "    * [2.1. Load Libraries](#1.1)    \n",
    "    * [2.2. Load Dataset](#1.2)\n",
    "* [3. Exploratory Data Analysis](#2)\n",
    "    * [3.1 Descriptive Statistics](#2.1) \n",
    "* [4. Data Preparation](#3)\n",
    "    * [4.1 Data Cleaning](#3.1)\n",
    "    * [4.2. Preparing classification data](#3.2)\n",
    "    * [4.3. Feature Engineering-Constructing Technical Indicators](#3.3)\n",
    "    * [4.4.Data Visualisation](#3.4)\n",
    "* [5.Evaluate Algorithms and Models](#4)        \n",
    "    * [5.1. Train/Test Split](#4.1)\n",
    "    * [5.2. Test Options and Evaluation Metrics](#4.2)\n",
    "    * [5.3. Compare Models and Algorithms](#4.3) \n",
    "* [6. Model Tuning and Grid Search](#5)  \n",
    "* [7. Finalize the Model](#6)  \n",
    "    * [7.1. Results on test dataset](#6.1)\n",
    "    * [7.1. Variable Intuition/Feature Selection](#6.2) \n",
    "* [8. Backtesting](#7)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of predicting a buy or sell signal for a trading strategy is defined in the\n",
    "classification framework, where the predicted variable has a value of 1 for buy and 0\n",
    "for sell.\n",
    "\n",
    "The buy or sell signal are decided on the basis on the comparison of short term vs. long\n",
    "term price.\n",
    "\n",
    "For the purpose of presented case study, we get the data from one of the largest Bit‐\n",
    "coin exchanges in terms of average daily volume traded—Bitstamp (https://\n",
    "www.bitstamp.com). Data can be found at: https://www.kaggle.com/mczielinski/bitcoin-historical-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# 2. Getting Started- Loading the data and python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Loading the python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:22:14.044521Z",
     "start_time": "2022-05-09T22:22:13.292420Z"
    },
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:22:17.283433Z",
     "start_time": "2022-05-09T22:22:17.020079Z"
    },
    "_cell_guid": "787e35f7-bf9e-0969-8d13-a54fa87f3519"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BitstampData_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fb62a4424316>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BitstampData_sample.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BitstampData_sample.csv'"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv('BitstampData_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.494496Z",
     "start_time": "2022-05-09T22:17:27.289Z"
    }
   },
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "df6a4523-b385-69ee-c933-592826d81431"
   },
   "source": [
    "<a id='2'></a>\n",
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 3.1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.499508Z",
     "start_time": "2022-05-09T22:17:38.172Z"
    },
    "_cell_guid": "52f85dc2-0f91-3c50-400e-ddc38bea966b"
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.507629Z",
     "start_time": "2022-05-09T22:17:38.387Z"
    }
   },
   "outputs": [],
   "source": [
    "# peek at data\n",
    "set_option('display.width', 100)\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.514705Z",
     "start_time": "2022-05-09T22:17:38.934Z"
    },
    "_cell_guid": "7bffeec0-5bbc-fffb-18f2-3da56b862ca3"
   },
   "outputs": [],
   "source": [
    "# describe data\n",
    "set_option('precision', 3)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "## 4.1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.519729Z",
     "start_time": "2022-05-09T22:17:39.823Z"
    }
   },
   "outputs": [],
   "source": [
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values =',dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are null values, we need to clean the data by filling the *NaNs* with the last available values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.524752Z",
     "start_time": "2022-05-09T22:17:40.413Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[dataset.columns.values] = dataset[dataset.columns.values].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.524752Z",
     "start_time": "2022-05-09T22:17:40.597Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset=dataset.drop(columns=['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2. Preparing the data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attach a label to each movement: \n",
    "* **1** if the signal is that short term price will go up as compared to the long term. \n",
    "* **0** if the signal is that short term price will go down as compared to the long term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.534398Z",
     "start_time": "2022-05-09T22:17:41.135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the `signals` DataFrame with the `signal` column\n",
    "#datas['PriceMove'] = 0.0\n",
    "\n",
    "# Create short simple moving average over the short window\n",
    "dataset['short_mavg'] = dataset['Close'].rolling(window=10, min_periods=1, center=False).mean()\n",
    "\n",
    "# Create long simple moving average over the long window\n",
    "dataset['long_mavg'] = dataset['Close'].rolling(window=60, min_periods=1, center=False).mean()\n",
    "\n",
    "# Create signals\n",
    "dataset['signal'] = np.where(dataset['short_mavg'] > dataset['long_mavg'], 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.539407Z",
     "start_time": "2022-05-09T22:17:41.321Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "## 4.3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by the constructing a dataset that contains the predictors which will be used to make the predictions, and the output variable.\n",
    "\n",
    "The current Data of the bicoin consists of date, open, high, low, close and Volume. Using this data we calculate the following  technical indicators:\n",
    "* **Moving Average** : A moving average provides an indication of the trend of the price movement by cut down the amount of \"noise\" on a price chart. \n",
    "* **Stochastic Oscillator %K and %D** : A stochastic oscillator is a momentum indicator comparing a particular closing price of a security to a range of its prices over a certain period of time. %K and %D are slow and fast indicators.\n",
    "* **Relative Strength Index(RSI)** :It is a momentum indicator that measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock or other asset. \n",
    "* **Rate Of Change(ROC)**: It is a momentum oscillator, which measures the percentage change between the current price and the n period past price. \n",
    "* **Momentum (MOM)** : It is the rate of acceleration of a security's price or volume – that is, the speed at which the price is changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.544484Z",
     "start_time": "2022-05-09T22:17:43.047Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculation of exponential moving average\n",
    "def EMA(df, n):\n",
    "    EMA = pd.Series(df['Close'].ewm(span=n, min_periods=n).mean(), name='EMA_' + str(n))\n",
    "    return EMA\n",
    "dataset['EMA10'] = EMA(dataset, 10)\n",
    "dataset['EMA30'] = EMA(dataset, 30)\n",
    "dataset['EMA200'] = EMA(dataset, 200)\n",
    "dataset.head()\n",
    "\n",
    "#calculation of rate of change\n",
    "def ROC(df, n):  \n",
    "    M = df.diff(n - 1)  \n",
    "    N = df.shift(n - 1)  \n",
    "    ROC = pd.Series(((M / N) * 100), name = 'ROC_' + str(n))   \n",
    "    return ROC\n",
    "dataset['ROC10'] = ROC(dataset['Close'], 10)\n",
    "dataset['ROC30'] = ROC(dataset['Close'], 30)\n",
    "\n",
    "#Calculation of price momentum\n",
    "def MOM(df, n):   \n",
    "    MOM = pd.Series(df.diff(n), name='Momentum_' + str(n))   \n",
    "    return MOM\n",
    "dataset['MOM10'] = MOM(dataset['Close'], 10)\n",
    "dataset['MOM30'] = MOM(dataset['Close'], 30)\n",
    "\n",
    "#calculation of relative strength index\n",
    "def RSI(series, period):\n",
    " delta = series.diff().dropna()\n",
    " u = delta * 0\n",
    " d = u.copy()\n",
    " u[delta > 0] = delta[delta > 0]\n",
    " d[delta < 0] = -delta[delta < 0]\n",
    " u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    " u = u.drop(u.index[:(period-1)])\n",
    " d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    " d = d.drop(d.index[:(period-1)])\n",
    " rs = u.ewm(com=period-1, adjust=False).mean() / \\\n",
    " d.ewm(com=period-1, adjust=False).mean()\n",
    " return 100 - 100 / (1 + rs)\n",
    "dataset['RSI10'] = RSI(dataset['Close'], 10)\n",
    "dataset['RSI30'] = RSI(dataset['Close'], 30)\n",
    "dataset['RSI200'] = RSI(dataset['Close'], 200)\n",
    "\n",
    "#calculation of stochastic osillator.\n",
    "\n",
    "def STOK(close, low, high, n): \n",
    " STOK = ((close - low.rolling(n).min()) / (high.rolling(n).max() - low.rolling(n).min())) * 100\n",
    " return STOK\n",
    "\n",
    "def STOD(close, low, high, n):\n",
    " STOK = ((close - low.rolling(n).min()) / (high.rolling(n).max() - low.rolling(n).min())) * 100\n",
    " STOD = STOK.rolling(3).mean()\n",
    " return STOD\n",
    "\n",
    "dataset['%K10'] = STOK(dataset['Close'], dataset['Low'], dataset['High'], 10)\n",
    "dataset['%D10'] = STOD(dataset['Close'], dataset['Low'], dataset['High'], 10)\n",
    "dataset['%K30'] = STOK(dataset['Close'], dataset['Low'], dataset['High'], 30)\n",
    "dataset['%D30'] = STOD(dataset['Close'], dataset['Low'], dataset['High'], 30)\n",
    "dataset['%K200'] = STOK(dataset['Close'], dataset['Low'], dataset['High'], 200)\n",
    "dataset['%D200'] = STOD(dataset['Close'], dataset['Low'], dataset['High'], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.547716Z",
     "start_time": "2022-05-09T22:17:43.517Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculation of moving average\n",
    "def MA(df, n):\n",
    "    MA = pd.Series(df['Close'].rolling(n, min_periods=n).mean(), name='MA_' + str(n))\n",
    "    return MA\n",
    "dataset['MA21'] = MA(dataset, 10)\n",
    "dataset['MA63'] = MA(dataset, 30)\n",
    "dataset['MA252'] = MA(dataset, 200)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.555876Z",
     "start_time": "2022-05-09T22:17:43.877Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.555876Z",
     "start_time": "2022-05-09T22:17:44.069Z"
    }
   },
   "outputs": [],
   "source": [
    "#excluding columns that are not needed for our prediction.\n",
    "\n",
    "dataset=dataset.drop(['High','Low','Open', 'Volume_(Currency)','short_mavg','long_mavg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.566756Z",
     "start_time": "2022-05-09T22:17:44.253Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.571025Z",
     "start_time": "2022-05-09T22:17:44.669Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "## 4.4. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.576093Z",
     "start_time": "2022-05-09T22:17:45.503Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[['Weighted_Price']].plot(grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.580563Z",
     "start_time": "2022-05-09T22:17:45.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.586282Z",
     "start_time": "2022-05-09T22:17:45.907Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot = dataset.groupby(['signal']).size().plot(kind='barh', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted variable is upward 52.87% out of total data-size, meaning that number\n",
    "of the buy signals were more than the number of sell signals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.590414Z",
     "start_time": "2022-05-09T22:17:46.666Z"
    }
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "correlation = dataset.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# 5. Evaluate Algorithms and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1. Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into 80% training set and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.593204Z",
     "start_time": "2022-05-09T22:17:48.031Z"
    }
   },
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "subset_dataset= dataset.iloc[-100000:]\n",
    "Y= subset_dataset[\"signal\"]\n",
    "X = subset_dataset.loc[:, dataset.columns != 'signal']\n",
    "validation_size = 0.2\n",
    "seed = 1\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2. Test Options and Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.597286Z",
     "start_time": "2022-05-09T22:17:48.553Z"
    },
    "_cell_guid": "5702bc31-06bf-8b6a-42de-366a6b3311a8"
   },
   "outputs": [],
   "source": [
    "# test options for classification\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "#scoring = 'precision'\n",
    "#scoring = 'recall'\n",
    "#scoring ='neg_log_loss'\n",
    "#scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3. Compare Models and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know which algorithm technic is the best for our strategy, we evaluate following non linear different methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.1'></a>\n",
    "### 5.3.1. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.604710Z",
     "start_time": "2022-05-09T22:17:49.955Z"
    },
    "_cell_guid": "772802f7-f4e4-84ee-6377-6464ab2e5da4"
   },
   "outputs": [],
   "source": [
    "# spot check the algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(n_jobs=-1)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#Neural Network\n",
    "models.append(('NN', MLPClassifier()))\n",
    "#Ensable Models \n",
    "# Boosting methods\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "models.append(('RF', RandomForestClassifier(n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.608044Z",
     "start_time": "2022-05-09T22:17:50.734Z"
    },
    "_cell_guid": "a784ab4a-eb59-98cc-76cf-b55f382d057a"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.615647Z",
     "start_time": "2022-05-09T22:17:50.940Z"
    },
    "_cell_guid": "67873e9d-bc9b-6963-f594-805f1efbfbb3"
   },
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# 6. Model Tuning and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "848ca488-b0fd-8e93-2e68-23d32c71d89c"
   },
   "source": [
    "Random forest is selected for the grid search as it is one of the best models out of all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.622426Z",
     "start_time": "2022-05-09T22:17:51.791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grid Search: Random Forest Classifier\n",
    "'''\n",
    "n_estimators : int (default=100)\n",
    "    The number of boosting stages to perform. \n",
    "    Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "max_depth : integer, optional (default=3)\n",
    "    maximum depth of the individual regression estimators. \n",
    "    The maximum depth limits the number of nodes in the tree. \n",
    "    Tune this parameter for best performance; the best value depends on the interaction of the input variables    \n",
    "criterion : string, optional (default=”gini”)\n",
    "    The function to measure the quality of a split. \n",
    "    Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. \n",
    "    \n",
    "'''   \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "n_estimators = [20,80]\n",
    "max_depth= [5,10]\n",
    "criterion = [\"gini\",\"entropy\"]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, criterion = criterion )\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "#Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# 7. Finalise the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizing the model with best parameters found during tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1. Results on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.629469Z",
     "start_time": "2022-05-09T22:17:52.616Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = RandomForestClassifier(criterion='gini', n_estimators=80,max_depth=10,n_jobs=-1) # rbf is default kernel\n",
    "#model = LogisticRegression() \n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.634311Z",
     "start_time": "2022-05-09T22:17:52.815Z"
    },
    "_cell_guid": "f9725666-3c21-69d1-ddf6-45e47d982444"
   },
   "outputs": [],
   "source": [
    "# estimate accuracy on validation set\n",
    "predictions = model.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.638807Z",
     "start_time": "2022-05-09T22:17:53.000Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix(Y_validation, predictions), columns=np.unique(Y_validation), index = np.unique(Y_validation))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2. Variable Intuition/Feature Importance\n",
    "Let us look into the Feature Importance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.638807Z",
     "start_time": "2022-05-09T22:17:53.373Z"
    }
   },
   "outputs": [],
   "source": [
    "Importance = pd.DataFrame({'Importance':model.feature_importances_*100}, index=X.columns)\n",
    "Importance.sort_values('Importance', axis=0, ascending=True).plot(kind='barh', color='r' )\n",
    "plt.xlabel('Variable Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "## 8. Backtesting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:17:54.648136Z",
     "start_time": "2022-05-09T22:17:53.794Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create column for Strategy Returns by multiplying the daily returns by the position that was held at close\n",
    "#of business the previous day\n",
    "backtestdata = pd.DataFrame(index=X_validation.index)\n",
    "#backtestdata = pd.DataFrame()\n",
    "backtestdata['signal_pred'] = predictions\n",
    "backtestdata['signal_actual'] = Y_validation\n",
    "backtestdata['Market Returns'] = X_validation['Close'].pct_change()\n",
    "backtestdata['Actual Returns'] = backtestdata['Market Returns'] * backtestdata['signal_actual'].shift(1)\n",
    "backtestdata['Strategy Returns'] = backtestdata['Market Returns'] * backtestdata['signal_pred'].shift(1)\n",
    "backtestdata=backtestdata.reset_index()\n",
    "backtestdata.head()\n",
    "backtestdata[['Strategy Returns','Actual Returns']].cumsum().hist()\n",
    "backtestdata[['Strategy Returns','Actual Returns']].cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__:\n",
    "\n",
    "We showed that framing the problem is the first priority and we address it by engi‐\n",
    "neering the features and transforming the labels according to the investment objective.\n",
    "\n",
    "We demonstrated the efficiency of using feature engineering that leads to creation of\n",
    "intuitive features related to the trend and momentum of the price movement and\n",
    "increases the predictive power of the model.\n",
    "\n",
    "In terms of the evaluation metrics for a classification-based trading strategy, accuracy\n",
    "or auc are appropriate, but in case the strategy is focusing to be more accurate while\n",
    "going long, the metric recall which focuses on less false positive can be preferred as\n",
    "compared to accuracy.\n",
    "\n",
    "Finally, we demonstrated the backtesting framework which allows us to simulate a\n",
    "trading strategy using historical data to generate results and analyze risk and profita‐\n",
    "bility before risking any actual capital.\n"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
